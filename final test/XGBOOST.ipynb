{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aCoderChild/Kaggle-and-AI/blob/main/final%20test/XGBOOST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FbKLStDJLV8E"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "P4Qpohl6LV8H"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YH2GbdQ4LV8H"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/aCoderChild/Kaggle-and-AI/refs/heads/main/final%20test/data/train.csv')\n",
        "df_test = pd.read_csv('https://raw.githubusercontent.com/aCoderChild/Kaggle-and-AI/refs/heads/main/final%20test/data/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7f25L15NLV8I"
      },
      "outputs": [],
      "source": [
        "def preprocessing_data(df):\n",
        "    df['person_education'].replace({\n",
        "            'High School': 0,\n",
        "            'Associate': 1,\n",
        "            'Bachelor': 2,\n",
        "            'Master': 3,\n",
        "            'Doctorate':4\n",
        "        }, inplace=True)\n",
        "\n",
        "    gender_mapping = {'male': 0, 'female': 1}\n",
        "    home_ownership_mapping = {'RENT': 0, 'OWN': 1, 'MORTGAGE': 2, 'OTHER': 3}\n",
        "    loan_intent_mapping = {'PERSONAL': 0, 'EDUCATION': 1, 'MEDICAL': 2, 'VENTURE': 3, 'HOMEIMPROVEMENT': 4, 'DEBTCONSOLIDATION': 5}\n",
        "    previous_loan_defaults_mapping = {'No': 0, 'Yes': 1}\n",
        "\n",
        "\n",
        "    df['person_gender'] = df['person_gender'].map(gender_mapping)\n",
        "    df['person_home_ownership'] = df['person_home_ownership'].map(home_ownership_mapping)\n",
        "    df['loan_intent'] = df['loan_intent'].map(loan_intent_mapping)\n",
        "    df['previous_loan_defaults_on_file'] = df['previous_loan_defaults_on_file'].map(previous_loan_defaults_mapping)\n",
        "\n",
        "    return df # preprocess the data, turning the String data into int for easier training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIhhqWzxLV8I",
        "outputId": "6f515891-9b27-4cc1-8b86-d97beba19d6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-4c67094b7d09>:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['person_education'].replace({\n",
            "<ipython-input-4-4c67094b7d09>:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df['person_education'].replace({\n",
            "<ipython-input-4-4c67094b7d09>:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['person_education'].replace({\n",
            "<ipython-input-4-4c67094b7d09>:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df['person_education'].replace({\n"
          ]
        }
      ],
      "source": [
        "df = preprocessing_data(df)\n",
        "df_test = preprocessing_data(df_test) # preprocess the training tand testing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "TpGBU0Z2LV8J",
        "outputId": "4fa22d16-f1c4-4083-cec2-1c084b431e32"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       person_age  person_gender  person_education  person_income  \\\n",
              "0            22.0              1                 3        71948.0   \n",
              "1            21.0              1                 0        12282.0   \n",
              "2            25.0              1                 0        12438.0   \n",
              "3            23.0              1                 2        79753.0   \n",
              "4            24.0              0                 3        66135.0   \n",
              "...           ...            ...               ...            ...   \n",
              "32994        35.0              0                 0        87428.0   \n",
              "32995        26.0              1                 2        91318.0   \n",
              "32996        23.0              1                 2        79749.0   \n",
              "32997        25.0              0                 0        51450.0   \n",
              "32998        35.0              0                 2        70632.0   \n",
              "\n",
              "       person_emp_exp  person_home_ownership  loan_amnt  loan_intent  \\\n",
              "0                   0                      0    35000.0            0   \n",
              "1                   0                      1     1000.0            1   \n",
              "2                   3                      2     5500.0            2   \n",
              "3                   0                      0    35000.0            2   \n",
              "4                   1                      0    35000.0            2   \n",
              "...               ...                    ...        ...          ...   \n",
              "32994              10                      2    12888.0            2   \n",
              "32995               6                      2     8000.0            3   \n",
              "32996               0                      0    16800.0            0   \n",
              "32997               1                      0     6000.0            2   \n",
              "32998              12                      0     7500.0            5   \n",
              "\n",
              "       loan_int_rate  loan_percent_income  cb_person_cred_hist_length  \\\n",
              "0              16.02                 0.49                         3.0   \n",
              "1              11.14                 0.08                         2.0   \n",
              "2              12.87                 0.44                         3.0   \n",
              "3              15.23                 0.44                         2.0   \n",
              "4              14.27                 0.53                         4.0   \n",
              "...              ...                  ...                         ...   \n",
              "32994           6.47                 0.15                         7.0   \n",
              "32995          14.92                 0.09                         5.0   \n",
              "32996          11.28                 0.21                         2.0   \n",
              "32997          12.48                 0.12                         3.0   \n",
              "32998          11.61                 0.11                        14.0   \n",
              "\n",
              "       credit_score  previous_loan_defaults_on_file  loan_status  \n",
              "0               561                               0            1  \n",
              "1               504                               1            0  \n",
              "2               635                               0            1  \n",
              "3               675                               0            1  \n",
              "4               586                               0            1  \n",
              "...             ...                             ...          ...  \n",
              "32994           664                               1            0  \n",
              "32995           590                               1            0  \n",
              "32996           632                               0            0  \n",
              "32997           661                               0            0  \n",
              "32998           703                               0            0  \n",
              "\n",
              "[32999 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-93e0b2b1-4009-4d4d-9c6a-e828de7569f6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>person_age</th>\n",
              "      <th>person_gender</th>\n",
              "      <th>person_education</th>\n",
              "      <th>person_income</th>\n",
              "      <th>person_emp_exp</th>\n",
              "      <th>person_home_ownership</th>\n",
              "      <th>loan_amnt</th>\n",
              "      <th>loan_intent</th>\n",
              "      <th>loan_int_rate</th>\n",
              "      <th>loan_percent_income</th>\n",
              "      <th>cb_person_cred_hist_length</th>\n",
              "      <th>credit_score</th>\n",
              "      <th>previous_loan_defaults_on_file</th>\n",
              "      <th>loan_status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>71948.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35000.0</td>\n",
              "      <td>0</td>\n",
              "      <td>16.02</td>\n",
              "      <td>0.49</td>\n",
              "      <td>3.0</td>\n",
              "      <td>561</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>12282.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>11.14</td>\n",
              "      <td>0.08</td>\n",
              "      <td>2.0</td>\n",
              "      <td>504</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>25.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>12438.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>5500.0</td>\n",
              "      <td>2</td>\n",
              "      <td>12.87</td>\n",
              "      <td>0.44</td>\n",
              "      <td>3.0</td>\n",
              "      <td>635</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>79753.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>15.23</td>\n",
              "      <td>0.44</td>\n",
              "      <td>2.0</td>\n",
              "      <td>675</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>24.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>66135.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>35000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>14.27</td>\n",
              "      <td>0.53</td>\n",
              "      <td>4.0</td>\n",
              "      <td>586</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32994</th>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>87428.0</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>12888.0</td>\n",
              "      <td>2</td>\n",
              "      <td>6.47</td>\n",
              "      <td>0.15</td>\n",
              "      <td>7.0</td>\n",
              "      <td>664</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32995</th>\n",
              "      <td>26.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>91318.0</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>8000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>14.92</td>\n",
              "      <td>0.09</td>\n",
              "      <td>5.0</td>\n",
              "      <td>590</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32996</th>\n",
              "      <td>23.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>79749.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16800.0</td>\n",
              "      <td>0</td>\n",
              "      <td>11.28</td>\n",
              "      <td>0.21</td>\n",
              "      <td>2.0</td>\n",
              "      <td>632</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32997</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>51450.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>12.48</td>\n",
              "      <td>0.12</td>\n",
              "      <td>3.0</td>\n",
              "      <td>661</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32998</th>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>70632.0</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>5</td>\n",
              "      <td>11.61</td>\n",
              "      <td>0.11</td>\n",
              "      <td>14.0</td>\n",
              "      <td>703</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>32999 rows × 14 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93e0b2b1-4009-4d4d-9c6a-e828de7569f6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-93e0b2b1-4009-4d4d-9c6a-e828de7569f6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-93e0b2b1-4009-4d4d-9c6a-e828de7569f6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5eaed164-7e6b-4db4-b3d5-0fa41ab0f137\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5eaed164-7e6b-4db4-b3d5-0fa41ab0f137')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5eaed164-7e6b-4db4-b3d5-0fa41ab0f137 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_32948ef9-ffb8-440b-ac18-007f27979818\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_32948ef9-ffb8-440b-ac18-007f27979818 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 32999,\n  \"fields\": [\n    {\n      \"column\": \"person_age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.333872051856216,\n        \"min\": 20.0,\n        \"max\": 144.0,\n        \"num_unique_values\": 58,\n        \"samples\": [\n          22.0,\n          26.0,\n          65.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"person_gender\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"person_education\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"person_income\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 74257.87799075092,\n        \"min\": 8000.0,\n        \"max\": 7200766.0,\n        \"num_unique_values\": 26614,\n        \"samples\": [\n          57716.0,\n          63285.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"person_emp_exp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 0,\n        \"max\": 125,\n        \"num_unique_values\": 61,\n        \"samples\": [\n          0,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"person_home_ownership\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"loan_amnt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6317.895437591368,\n        \"min\": 500.0,\n        \"max\": 35000.0,\n        \"num_unique_values\": 887,\n        \"samples\": [\n          800.0,\n          4775.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"loan_intent\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"loan_int_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.069164453158536,\n        \"min\": 5.42,\n        \"max\": 20.0,\n        \"num_unique_values\": 567,\n        \"samples\": [\n          11.85,\n          12.13\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"loan_percent_income\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08678296667041241,\n        \"min\": 0.0,\n        \"max\": 0.66,\n        \"num_unique_values\": 62,\n        \"samples\": [\n          0.0,\n          0.62\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cb_person_cred_hist_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.050482634432875,\n        \"min\": 2.0,\n        \"max\": 30.0,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          24.0,\n          25.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"credit_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 50,\n        \"min\": 390,\n        \"max\": 850,\n        \"num_unique_values\": 331,\n        \"samples\": [\n          626,\n          748\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"previous_loan_defaults_on_file\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"loan_status\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df # print the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8VX7TCIjLV8J"
      },
      "outputs": [],
      "source": [
        "X = df.drop(['loan_status'], axis = 1)\n",
        "y = df['loan_status']\n",
        "# X and Y vectors of training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xfFXpMK3LV8J"
      },
      "outputs": [],
      "source": [
        "XX = df_test.drop(['loan_status'], axis = 1)\n",
        "yy = df_test['loan_status']\n",
        "# X and Y vectors of testing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22-fB8ESLV8K"
      },
      "source": [
        "# XGBoost Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "57KYldMBLV8K"
      },
      "outputs": [],
      "source": [
        "class XGBClassifier():\n",
        "    '''\n",
        "        Model represents part of XGBoost model in Python library\n",
        "        Based on the paper about XGBoost: https://www.kdd.org/kdd2016/papers/files/rfp0697-chenAemb.pdf\n",
        "        The Model does NOT represent full features of xgboostclassifier in xgb library\n",
        "        Model uses tree_method = 'exact'\n",
        "    '''\n",
        "    def __init__(self, params, random_seed=None):\n",
        "        '''\n",
        "            Constructor XGBoostModel\n",
        "\n",
        "            params: A dictionary of hyperparameters used for training the model\n",
        "            (like learning rate, maximum depth, etc.).\n",
        "            If any parameter is missing, it will use a default value.\n",
        "\n",
        "            random_seed: random numbers - seed for randoms\n",
        "        '''\n",
        "        self.params = defaultdict(lambda: None, params)\n",
        "\n",
        "        # Subsample: fraction of data to use for each boosting round. If not specified, it uses 1.0 (i.e., the entire dataset)\n",
        "        if 'subsample' in self.params and self.params['subsample']:\n",
        "            self.subsample = self.params['subsample']\n",
        "        else:\n",
        "            self.subsample = 1.0\n",
        "\n",
        "        # Learning rate in [0,1]: Controls how much each tree should contribute to the final prediction. It defaults to 0.3\n",
        "        if 'learning_rate' in self.params and self.params['learning_rate']:\n",
        "            self.learning_rate = self.params['learning_rate']\n",
        "        else:\n",
        "            self.learning_rate = 0.3\n",
        "\n",
        "        # Base predict score: The initial prediction for all samples. If not specified, it defaults to 0.5.\n",
        "        if 'base_score' in params and params['base_score']:\n",
        "            self.base_score = params['base_score']\n",
        "        else:\n",
        "            self.base_score = 0.5\n",
        "\n",
        "        # Maximum depth of a decision tree, value in [1,∞]. If not specified, it defaults to 5\n",
        "        if 'max_depth' in params and params['max_depth']:\n",
        "            self.max_depth = params['max_depth']\n",
        "        else:\n",
        "            self.max_depth = 5\n",
        "\n",
        "        # Random_seed\n",
        "        self.rng = np.random.default_rng(seed=random_seed)\n",
        "\n",
        "\n",
        "    def fit(self, X, y, LossFunction, n_estimators):\n",
        "        '''\n",
        "            Provide data for the model and execute training\n",
        "\n",
        "            X: training data\n",
        "            y: training label\n",
        "            LossFunction: target function for training\n",
        "            n_estimators: a number of boosting iterations or the number of decision trees built\n",
        "        '''\n",
        "        # Starts with a baseline prediction (base_score) for all samples, which is initially set to 0.5. This will be updated as trees are added.\n",
        "        current_predictions = self.base_score * np.ones(shape=y.shape)\n",
        "\n",
        "        # TreeBoosters: A list to store the individual decision trees (boosters) built during training.\n",
        "        self.TreeBoosters = []\n",
        "        for i in range(n_estimators):\n",
        "\n",
        "            # Calculate gradients and hessians based on previous predictions\n",
        "            # First and second derivatives of the loss function\n",
        "            # They represent how much the current model's predictions need to change to improve\n",
        "            # Computed based on the currnet_predictions and the actual target values\n",
        "            gradients = LossFunction.gradient(y, current_predictions)\n",
        "            hessians = LossFunction.hessian(y, current_predictions)\n",
        "\n",
        "            # Data Subsampling:\n",
        "            #    If subsample is less than 1, a random subset (reduce overfitting) of the training data is selected for the current round.\n",
        "            #    If subsample equals 1, the entire dataset is used.\n",
        "            if self.subsample != 1.0:\n",
        "                sample_size = math.floor(self.subsample * len(y))\n",
        "                sample_idxs = self.rng.choice(len(y), size=sample_size, replace=False)\n",
        "            else:\n",
        "                sample_idxs = None\n",
        "\n",
        "            # Tree Building (Booster): A new tree (booster) is constructed using the gradients and hessians.\n",
        "            # It uses the training data, gradients, and hessians to build a decision tree.\n",
        "            booster = TreeBooster(X, gradients, hessians, self.params, self.max_depth, sample_idxs)\n",
        "\n",
        "            # Update Predictions: The current model’s predictions are updated by adding the new tree’s predictions, scaled by the learning_rate.\n",
        "            current_predictions += self.learning_rate * booster.predict(X)\n",
        "\n",
        "            # Store the Booster: The newly created tree is stored in the TreeBoosters list for later use in prediction.\n",
        "            self.TreeBoosters.append(booster)\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "        '''\n",
        "            predict the result based on the input data\n",
        "        '''\n",
        "        # Tree Contributions: For each tree in TreeBoosters, the predict method of each tree is called to get its contribution to the prediction for each sample in X.\n",
        "        TreeBoosters_predictions = [booster.predict(X) for booster in self.TreeBoosters]\n",
        "        # Calculate the total prediction\n",
        "        total_TreeBoosters_contribution = np.sum(TreeBoosters_predictions, axis=0)\n",
        "        # Calculate the predict\n",
        "        prediction = self.base_score + self.learning_rate * total_TreeBoosters_contribution\n",
        "\n",
        "        # Do predict for binary classification problem\n",
        "        y_pred = []\n",
        "        for i in prediction:\n",
        "            if i < 0.5:\n",
        "                y_pred.append(0)\n",
        "            else:\n",
        "                y_pred.append(1)\n",
        "        y_pred = np.array(y_pred)\n",
        "\n",
        "        return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "W9G5Bz3yLV8K"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "    The TreeBooster class is responsible for building and handling individual decision trees during the boosting process.\n",
        "\n",
        "    These trees are built iteratively and are designed to correct the residual errors of previous trees in the boosting sequence.\n",
        "\n",
        "    The key functions of this class are:\n",
        "       - Initialization (__init__): This sets up the tree and calculates the value at the root node.\n",
        "       - Child Node Creation (_maybe_insert_child_nodes): This tries to split the data further by finding the best split for each feature.\n",
        "       - Finding the Best Split (_find_better_split): This finds the best threshold for splitting the data based on a specific feature, considering both gradients and hessians.\n",
        "       - Prediction (predict): This makes predictions by traversing the tree.\n",
        "       - Leaf Node Check (is_leaf): This checks if the current node is a leaf node, meaning no further splits are needed.\n",
        "'''\n",
        "\n",
        "class TreeBooster():\n",
        "\n",
        "    def __init__(self, X, g, h, params, max_depth, idxs=None):\n",
        "        '''\n",
        "            Costruct Decision Tree or Subtree of Decision Tree (based on max_depth)\n",
        "\n",
        "            X: feature matrix (training data)\n",
        "            g: the gradients (first derivatives of loss function)\n",
        "            h: the hessians (second derivatives of loss function)\n",
        "            params: Hyperparameters such as regulatization, learning rate, etc.\n",
        "            max_depth: maximum depth of a tree, which controls how many levels of splitting the tree will have\n",
        "            idxs: The indices of the data points used in the current split. If None, it means the whole dataset is used.\n",
        "        '''\n",
        "\n",
        "        self.params = params\n",
        "        self.max_depth = max_depth\n",
        "\n",
        "        # Regularization hyperparameters\n",
        "        # They help prevent overfitting and control the model's complexity by adding constraints to how the tree is built\n",
        "\n",
        "        # Controls the minimum amount of \"cover\" (or sum of hessians) required in a child node.\n",
        "        # It helps in preventing overfitting by avoiding splits that result in overly small nodes with insufficient data.\n",
        "        self.min_child_weight = params.get('min_child_weight', 1.0)\n",
        "\n",
        "        # reg_lambda: L2 regularization\n",
        "        # This parameter adds a regularization term to the objective function, helping to control the complexity of the model by penalizing large weights.\n",
        "        self.reg_lambda = params.get('reg_lambda', 1.0)\n",
        "\n",
        "        # Specifies the minimum loss reduction required to make a further split.\n",
        "        # It sets a threshold for how much the gain (improvement in the objective function) must be for a split to be accepted.\n",
        "        # If the gain from a split is less than gamma, the split is rejected, and the tree doesn't grow further at that node.\n",
        "        self.gamma = params.get('gamma', 0.0)\n",
        "\n",
        "        # Converts the gradients (g) and hessians (h) to NumPy arrays for easier calculations.\n",
        "        if isinstance(g, pd.Series):\n",
        "            g = g.values\n",
        "        if isinstance(h, pd.Series):\n",
        "            h = h.values\n",
        "\n",
        "        # idxs = None <=> whole dataset\n",
        "        if idxs is None:\n",
        "            idxs = np.arange(len(g))\n",
        "\n",
        "        self.X = X  # Training data\n",
        "\n",
        "        self.g = g  # Calculated gradients during previous iterations\n",
        "        self.h = h  # Calculated Hessians during previous iterations\n",
        "\n",
        "        self.idxs = idxs    # Index of the data of X will be used\n",
        "        self.n = len(idxs)  # Number of samples\n",
        "        self.c = X.shape[1]  # Number of features\n",
        "\n",
        "        # Computes the initial value for the root node\n",
        "        self.value = -g[idxs].sum() / (h[idxs].sum() + self.reg_lambda)\n",
        "        # This is the predicted value for the node before any splitting.\n",
        "\n",
        "        # track the best split found during the process\n",
        "        self.best_score_so_far = 0.\n",
        "\n",
        "        # Recursion to split:\n",
        "        # If the tree's depth (max_depth) is greater than 0,\n",
        "        # the _maybe_insert_child_nodes method is called to attempt splitting the node further.\n",
        "        if self.max_depth > 0:\n",
        "            self._maybe_insert_child_nodes()\n",
        "\n",
        "\n",
        "    def _maybe_insert_child_nodes(self):\n",
        "\n",
        "        # It loops through all features (columns of X) and tries to find the best possible split\n",
        "        # using the _find_better_split method.\n",
        "        for feature_idx in range(self.c):\n",
        "            self._find_better_split(feature_idx)\n",
        "\n",
        "        # If it is leaf node, stop\n",
        "        if self.is_leaf:\n",
        "            return\n",
        "\n",
        "        # Take the value of the chosen feature for splitting\n",
        "        x = self.X.values[self.idxs, self.split_feature_idx]\n",
        "\n",
        "        # Divide the data into 2 groups based on the threshold calculated in _find_better_split()\n",
        "        left_idx = np.nonzero(x <= self.threshold)[0]\n",
        "        right_idx = np.nonzero(x > self.threshold)[0]\n",
        "\n",
        "        # Construct Left Node\n",
        "        self.left = TreeBooster(\n",
        "            self.X,\n",
        "            self.g,\n",
        "            self.h,\n",
        "            self.params,\n",
        "            self.max_depth - 1, # -1 max_depth\n",
        "            self.idxs[left_idx]\n",
        "        )\n",
        "\n",
        "        # Construct Right Node\n",
        "        self.right = TreeBooster(\n",
        "            self.X,\n",
        "            self.g,\n",
        "            self.h,\n",
        "            self.params,\n",
        "            self.max_depth - 1, # -1 max_depth\n",
        "            self.idxs[right_idx]\n",
        "        )\n",
        "\n",
        "\n",
        "    @property\n",
        "    def is_leaf(self):\n",
        "        '''\n",
        "            Check if the current Node is Leaf Node or not\n",
        "            If the splitting does NOT increase Gain => This Node is a Leaf Node\n",
        "        '''\n",
        "        if self.best_score_so_far == 0:\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "\n",
        "    def _find_better_split(self, feature_idx):\n",
        "        '''\n",
        "            Function finds the optimal splitting for Decision Tree\n",
        "            The Searching is practised by choosing 2 consecutive value in a sorted array\n",
        "            Taking the average of the 2 numbers as threshold. After that calculate Gain according to the threshold.\n",
        "            Finally, choose the threshold with the highest Gain\n",
        "\n",
        "            feature_idx: feature (column) - defined\n",
        "        '''\n",
        "\n",
        "        # Retreive feature value and gradient/hessian in respect\n",
        "        x = self.X.values[self.idxs, feature_idx]\n",
        "        g = self.g[self.idxs]\n",
        "        h = self.h[self.idxs]\n",
        "\n",
        "        # For the given feature (feature_idx), the values of that feature are sorted,\n",
        "        # along with the corresponding gradients (g) and hessians (h).\n",
        "        sort_idx = np.argsort(x)\n",
        "        sort_x = x[sort_idx]\n",
        "        sort_g = g[sort_idx]\n",
        "        sort_h = h[sort_idx]\n",
        "\n",
        "        # Total gradient (total_g) and total hessian (total_h) for the entire dataset.\n",
        "        total_g = g.sum()\n",
        "        total_h = h.sum()\n",
        "        sum_g_left, sum_h_left = 0.0, 0.0\n",
        "        sum_g_right, sum_h_right = total_g, total_h\n",
        "\n",
        "        # It then iterates through the sorted values and calculates the \"gain\" of splitting the data at each possible threshold.\n",
        "        '''\n",
        "            'exact': threshold is the average of two consecutive feature values\n",
        "        '''\n",
        "        for i in range(self.n - 1):\n",
        "            g_i = sort_g[i]\n",
        "            h_i = sort_h[i]\n",
        "            x_i = sort_x[i]\n",
        "            x_i_next = sort_x[i + 1] # Next value\n",
        "\n",
        "            # Update gradients và hessians of Left and Right Nodes\n",
        "            sum_g_left += g_i\n",
        "            sum_h_left += h_i\n",
        "            sum_g_right -= g_i\n",
        "            sum_h_right -= h_i\n",
        "\n",
        "            # Check Splitting condition\n",
        "            # If Cover smaller than min Cover: reject the node and stop splitting\n",
        "            # Cover = sigma h_i\n",
        "            if sum_h_left < self.min_child_weight or x_i == x_i_next:\n",
        "                continue\n",
        "            if sum_h_right < self.min_child_weight:\n",
        "                break\n",
        "\n",
        "            # Calculate Gain of the splitting according to formula (7) in paper\n",
        "            gain = (\n",
        "                0.5\n",
        "                * (\n",
        "                    (sum_g_left**2 / (sum_h_left + self.reg_lambda))\n",
        "                    + (sum_g_right**2 / (sum_h_right + self.reg_lambda))\n",
        "                    - (total_g**2 / (total_h + self.reg_lambda))\n",
        "                )\n",
        "                - self.gamma / 2\n",
        "            )\n",
        "\n",
        "            # Update if greater Gain found\n",
        "            if gain > self.best_score_so_far:\n",
        "                self.split_feature_idx = feature_idx\n",
        "                self.best_score_so_far = gain\n",
        "                self.threshold = (x_i + x_i_next) / 2\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        This method is responsible for making predictions using the trained tree.\n",
        "\n",
        "        It iterates over each row of the input X (which is a DataFrame), and for each row,\n",
        "        it calls _predict_row to traverse the tree and get the prediction for that specific row.\n",
        "        \"\"\"\n",
        "        predictions = []\n",
        "        for _, row in X.iterrows():\n",
        "            predictions.append(self._predict_row(row))\n",
        "        return np.array(predictions)\n",
        "\n",
        "\n",
        "    def _predict_row(self, row):\n",
        "        \"\"\"\n",
        "        Predict the value for a row of data\n",
        "        \"\"\"\n",
        "        # If the current node is a leaf, it returns the value stored at the leaf node (the predicted value for that node).\n",
        "        if self.is_leaf:\n",
        "            return self.value\n",
        "\n",
        "        # If the current node is not a leaf, it checks which child node (left or right)\n",
        "        # the row should go to based on the value of the feature at split_feature_idx and the threshold (threshold).\n",
        "        if row.iloc[self.split_feature_idx] <= self.threshold:\n",
        "            child = self.left\n",
        "        else:\n",
        "            child = self.right\n",
        "\n",
        "        # The method recursively calls _predict_row on the appropriate child node until it reaches a leaf node,\n",
        "        # and then it returns the predicted value at that leaf.\n",
        "        return child._predict_row(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "uTPyStFnLV8L"
      },
      "outputs": [],
      "source": [
        "class SquaredErrorObjective:\n",
        "    def loss(self, y, pred):\n",
        "        \"\"\"\n",
        "        Calculate Mean Squared Error (MSE).\n",
        "        \"\"\"\n",
        "        mse = np.mean((y - pred) ** 2)\n",
        "        return mse\n",
        "\n",
        "    def gradient(self, y, pred):\n",
        "        \"\"\"\n",
        "        Calculate Gradient of Mean Squared Error (MSE) in respect to each predicted value\n",
        "        First derivatives of loss function\n",
        "        \"\"\"\n",
        "        grad = pred - y\n",
        "        return grad\n",
        "\n",
        "    def hessian(self, y, pred):\n",
        "        \"\"\"\n",
        "        Calculate hessian of MSE.\n",
        "        Second derivatives of loss function\n",
        "        \"\"\"\n",
        "        hess = np.ones(len(y))\n",
        "        return hess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xx9EGIC6LV8L"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "The class LogLossObjective defines a custom loss function used in binary classification tasks,\n",
        "specifically for logistic regression or binary classification problems where the output is a probability.\n",
        "'''\n",
        "class LogLossObjective:\n",
        "    def loss(self, y, pred):\n",
        "        \"\"\"\n",
        "        This method computes the log loss (also known as binary cross-entropy)\n",
        "        between the true labels (y) and the predicted probabilities (pred).\n",
        "        \"\"\"\n",
        "        # epsilon = 1e-15  # Avoid log(0)\n",
        "        # pred = np.clip(pred, epsilon, 1 - epsilon)  # Limit the value to ensure stability\n",
        "        log_loss = -(y * np.log(pred) + (1 - y) * np.log(1 - pred))\n",
        "        # pred: The predicted probabilities, outputs from a model that has passed through a sigmoid function, ranging from 0 to 1.\n",
        "        return log_loss\n",
        "\n",
        "    def gradient(self, y, pred):\n",
        "        \"\"\"\n",
        "        This method calculates the gradient (first derivative) of the log loss function\n",
        "        with respect to the predicted values (pred).\n",
        "        \"\"\"\n",
        "        pred = 1.0 / (1.0 + np.exp(-pred))\n",
        "        grad = pred - y\n",
        "        return grad\n",
        "\n",
        "    def hessian(self, y, pred):\n",
        "        \"\"\"\n",
        "        This method calculates the Hessian (second derivative) of the log loss function\n",
        "        with respect to the predicted values (pred).\n",
        "\n",
        "        This is the second derivative of the log loss function and measures the curvature or the rate of change of the gradient.\n",
        "        \"\"\"\n",
        "        pred = 1.0 / (1.0 + np.exp(-pred))\n",
        "        hess = pred*(1-pred)\n",
        "        return hess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0XmirasLV8M"
      },
      "source": [
        "Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQkC7UAkLV8M",
        "outputId": "d1110597-0d9d-42f6-e05d-52654db782d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Times: 1\n",
            "Accuracy: 93.42%\n",
            "F1 Score: 85.35%\n",
            "Precision: 92.14%\n",
            "Recall: 79.50%\n",
            "\n",
            "{'learning_rate': 0.37708681042741465, 'max_depth': 14, 'subsample': 0.8276106690828566, 'reg_lambda': 1.0, 'gamma': 0.0, 'min_child_weight': 2.327996464162829, 'base_score': 0.75}\n",
            "n_estimators: 97\n",
            "Train running time: 956.773480 giây\n",
            "Test: 125.543827 giây\n",
            "\n",
            "\n",
            "Times: 2\n",
            "Accuracy: 93.55%\n",
            "F1 Score: 85.61%\n",
            "Precision: 92.60%\n",
            "Recall: 79.60%\n",
            "\n",
            "{'learning_rate': 0.28350321158658337, 'max_depth': 20, 'subsample': 0.8491392043936676, 'reg_lambda': 1.0, 'gamma': 0.0, 'min_child_weight': 1.6515391642057178, 'base_score': 0.75}\n",
            "n_estimators: 98\n",
            "Train running time: 1156.364107 giây\n",
            "Test: 133.794685 giây\n",
            "\n",
            "\n",
            "Times: 3\n",
            "Accuracy: 92.98%\n",
            "F1 Score: 84.31%\n",
            "Precision: 91.43%\n",
            "Recall: 78.22%\n",
            "\n",
            "{'learning_rate': 0.3776527486703133, 'max_depth': 17, 'subsample': 0.7731868148299113, 'reg_lambda': 1.0, 'gamma': 0.0, 'min_child_weight': 1.5739570998408616, 'base_score': 0.75}\n",
            "n_estimators: 66\n",
            "Train running time: 706.292588 giây\n",
            "Test: 85.290113 giây\n",
            "\n",
            "\n",
            "Times: 4\n"
          ]
        }
      ],
      "source": [
        "# multiple\n",
        "import time\n",
        "import random\n",
        "\n",
        "for i in range(0,100):\n",
        "    print(f\"Times: {i+1}\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    params = {\n",
        "        'learning_rate': random.uniform(0.2, 0.4),\n",
        "        'max_depth': random.randint(12, 20),\n",
        "        'subsample': random.uniform(0.7, 0.9),\n",
        "        'reg_lambda': 1.0,\n",
        "        'gamma': 0.0,\n",
        "        'min_child_weight': random.uniform(1.0, 3.0),\n",
        "        'base_score': 0.75,\n",
        "    }\n",
        "    n_estimators = random.randint(50, 100)\n",
        "\n",
        "    # train the from-scratch XGBoost model\n",
        "    model_scratch = XGBClassifier(params, random_seed=42)\n",
        "    # Can use 1 of 2 loss functions:\n",
        "    # LogLossObjective() or SquaredErrorObjective()\n",
        "    model_scratch.fit(X, y, LogLossObjective(), n_estimators) #fit model\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Running time\n",
        "    elapsed_train_time = end_time - start_time\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    pred_scratch = model_scratch.predict(XX)\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed_test_time = end_time - start_time\n",
        "\n",
        "    accuracy = accuracy_score(yy, pred_scratch)\n",
        "    f1 = f1_score(yy, pred_scratch)\n",
        "    precision = precision_score(yy, pred_scratch)\n",
        "    recall = recall_score(yy, pred_scratch)\n",
        "    # confusion_matrix = confusion_matrix(yy, pred_scratch)\n",
        "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "    print(f\"F1 Score: {f1 * 100:.2f}%\")\n",
        "    print(f\"Precision: {precision * 100:.2f}%\")\n",
        "    print(f\"Recall: {recall * 100:.2f}%\")\n",
        "    print(\"\")\n",
        "    print(params)\n",
        "    print(f\"n_estimators: {n_estimators}\")\n",
        "\n",
        "    print(f\"Train running time: {elapsed_train_time:.6f} giây\")\n",
        "    print(f\"Test: {elapsed_test_time:.6f} giây\")\n",
        "    print(\"\")\n",
        "    print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oHvDud9HUWxj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 5969230,
          "sourceId": 9750039,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 6238003,
          "sourceId": 10111341,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 6251274,
          "sourceId": 10129484,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30804,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}